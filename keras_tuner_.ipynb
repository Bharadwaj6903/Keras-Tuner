{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFdPvlXBOdUN"
      },
      "source": [
        "# Introduction to the Keras Tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/keras_tuner\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/keras/keras_tuner.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxb-dlhMIzW"
      },
      "source": [
        "## Overview\n",
        "\n",
        "The Keras Tuner is a library that helps you pick the optimal set of hyperparameters for your TensorFlow program. The process of selecting the right set of hyperparameters for your machine learning (ML) application is called *hyperparameter tuning* or *hypertuning*.\n",
        "\n",
        "Hyperparameters are the variables that govern the training process and the topology of an ML model. These variables remain constant over the training process and directly impact the performance of your ML program. Hyperparameters are of two types:\n",
        "1. **Model hyperparameters** which influence model selection such as the number and width of hidden layers\n",
        "2. **Algorithm hyperparameters** which influence the speed and quality of the learning algorithm such as the learning rate for Stochastic Gradient Descent (SGD) and the number of nearest neighbors for a k Nearest Neighbors (KNN) classifier\n",
        "\n",
        "In this tutorial, you will use the Keras Tuner to perform hypertuning for an image classification application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUXex9ctTuDB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g83Lwsy-Aq2_"
      },
      "source": [
        "Install and import the Keras Tuner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hpMLpbt9jcO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4455c7-de0d-429e-ca40-3b834015deb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_leAIdFKAxAD"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReV_UXOgCZvx"
      },
      "source": [
        "## Download and prepare the dataset\n",
        "\n",
        "In this tutorial, you will use the Keras Tuner to find the best hyperparameters for a machine learning model that classifies images of clothing from the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HljH_ENLEdHa"
      },
      "source": [
        "Load the data."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOvxg5ZAOFfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OHlHs9Wj_PUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a111f7f-ab57-4ce7-8c0d-7761332e347e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_train"
      ],
      "metadata": {
        "id": "j6UDAvfpOHpd",
        "outputId": "2ec182fd-172d-407a-eb5f-86daf749dedf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_train"
      ],
      "metadata": {
        "id": "RxSyXnW6OYkD",
        "outputId": "ecefba69-9f02-48bf-f22f-155a1bf28016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_train[0] #pixels 0-255"
      ],
      "metadata": {
        "id": "s4psBc34Ossf",
        "outputId": "329ab9d6-4f99-41d4-c34c-a0529341d5bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
              "          1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
              "          0,   3],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
              "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
              "         10,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
              "         72,  15],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
              "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
              "        172,  66],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
              "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
              "        229,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
              "        173,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
              "        202,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
              "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
              "        209,  52],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
              "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
              "        167,  56],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
              "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
              "         92,   0],\n",
              "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
              "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
              "         77,   0],\n",
              "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
              "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
              "        159,   0],\n",
              "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
              "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
              "        215,   0],\n",
              "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
              "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
              "        246,   0],\n",
              "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
              "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
              "        225,   0],\n",
              "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
              "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
              "        229,  29],\n",
              "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
              "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
              "        230,  67],\n",
              "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
              "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
              "        206, 115],\n",
              "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
              "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
              "        210,  92],\n",
              "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
              "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
              "        170,   0],\n",
              "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
              "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-6dd0d1d7-af86-4b14-9c2b-287207dc4849\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACBUlEQVR4nLXSz0tUURQH8O+597373rx545g6NmNJY6TlJgozEsKFZGCrkDBoVdGmdf9BiwJ3bVr1PwhBUbQfJQcKjWZRTsjo0KDpDPV+eN+997WK0Z2bvtsPfM+Bc4D/HwJycwBZAEAE6zAyfe5RFMQfFYiRAj+CXM/c2HK82VetVMM34RGUmCxz9v7yYnW9dnWyskyHR6azi72Jwep3ScVk9c7LLhKQrpRBSiI2n76puZFT3doUwH4pcmw/zpjrU2zw3dFt4XEWdvbKhpinzTBYt5bDH4qlLYO8cbKBWHOudDHluFtiLrLD0kmM2//6q9VFS+JLLDxv9GzMPV9v3XuzYgHEGSUGCngbRCLd4W6CxPCLHTDwVMkDA0y/qEa/lFFBoF2EEME8CAD6hsZK8+djlmSatuiXXsWfNh27NU6Yelro1bytPElRbaGaO1FGPfc7zPg9HvHlIaVD8AjID9y/+bgZ/6iP9ks7J/QZevh8w/cd2PlGs8CKt92R7MQEk0yA7GtWq9ETN3zRs7fpR7FaWi/3yXaipW1IjFnbaSM70N7dsRzbzbHd8aCx7+wmKskUO5esz0sPmvXYF67gBzoNfxptxb5stxM10iLg1pOTO23NhcUptW1hE6gFYYprC8QMMPNsMM+4pamVbps/HGkSsg+1Cv4d+0Jh//Sm3DjGix4rfwFoJNh2/0cDFgAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
              "          1,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
              "          0,   3],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
              "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
              "         10,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
              "         72,  15],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
              "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
              "        172,  66],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
              "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
              "        229,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
              "        173,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
              "        202,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
              "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
              "        209,  52],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
              "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
              "        167,  56],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
              "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
              "         92,   0],\n",
              "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
              "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
              "         77,   0],\n",
              "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
              "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
              "        159,   0],\n",
              "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
              "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
              "        215,   0],\n",
              "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
              "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
              "        246,   0],\n",
              "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
              "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
              "        225,   0],\n",
              "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
              "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
              "        229,  29],\n",
              "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
              "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
              "        230,  67],\n",
              "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
              "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
              "        206, 115],\n",
              "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
              "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
              "        210,  92],\n",
              "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
              "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
              "        170,   0],\n",
              "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
              "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-6dd0d1d7-af86-4b14-9c2b-287207dc4849 button').onclick = (e) => {\n",
              "        document.querySelector('#id-6dd0d1d7-af86-4b14-9c2b-287207dc4849').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-6dd0d1d7-af86-4b14-9c2b-287207dc4849 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_train[0]"
      ],
      "metadata": {
        "id": "ii-kwVSqPOGw",
        "outputId": "4534b55f-4629-4c40-fd4f-05ac242ca5a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_train[0].shape"
      ],
      "metadata": {
        "id": "hfF7s1XqPYDq",
        "outputId": "1da4f056-e994-46ce-ad51-50e074b4c7ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img_train[0], cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FkNfFB5RP6Rq",
        "outputId": "9c45fcf3-ec52-4dcd-fdd6-2fcdea45a0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img_train[1], cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2fvEKhQrQKDt",
        "outputId": "5850eee5-3a8c-4f5e-927b-85872f60abf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img_train[3], cmap='binary')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "36w-5CE0QmVU",
        "outputId": "4a46f6be-80d8-4b44-ac19-9cd2704529d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAANZElEQVR4nO3cvW/VdRvH8asPlNMHWlpSSIVQqBoTTRyM0egk0U39D2R1cHJ3cdSBkPhHuDkwGRMXNS6ODSYkBInWqlBrC4U+0Z5zb9dC7oTre989SHm99k9+p6fou7/lGuj1er0AgIgYfNwfAIB/D1EAIIkCAEkUAEiiAEASBQCSKACQRAGANPy4PwD/Xzdv3ixvvvvuu/LmypUr5c3MzEx5ExFx8eLF8uaVV14pb65du1befPXVV+XNt99+W95ERIyPj5c3H3zwQXnz4YcfljccHt4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQBnq9Xu9xf4jD7uuvvy5vLl++3PSs0dHR8mZ3d7e86XQ65c3du3fLm4iIn3/+uby5detWeXPu3LnyZni4flNybm6uvImImJqaKm92dnbKm99//728eeedd8qbL774orzh4HlTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAchCv6MaNG+XNp59+Wt6cPHmyvImI2NraKm+63W55MzhY/3ui5XhcRMTS0lLTrmpgYKC8GRoaKm8mJyfLm4iII0eOlDct3/mJEyfKm5YjesePHy9vIiIuXbrUtOPReFMAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSK6lFH330UXnT6XTKm5aLnRER9+/fL2+2t7fLm5broOPj4+VNRNulz6mpqfKm5Xto+T3t7OyUN61avruW3+3o6Gh5c/Xq1fImIuLixYvlzXvvvdf0rKeRNwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACQH8Yp++umn8uby5cvlzezsbHkTETE9PV3ebGxslDdHjhwpb1qNjIyUN2trawfwSR42OTlZ3rQcnOunlu97fX39//9B/otLly717VlPI28KACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIw4/7AzxpXnvttfLmjTfeKG+uXLlS3kREvP766+XN3t5eebO5uVnezMzMlDcRbQfaWg4Kdjqd8qble3jw4EF5ExExNTVV3ty+fbvpWVVbW1vlzWeffXYAn4T/lTcFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgCkgV6v13vcH4KHLSwsNO3eeuut8qbleNzgYP3vifHx8fImImJycrJpV9VyGLDlWF/LcyLaDum1HOy7c+dOeXPhwoXy5v333y9vOHjeFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkIYf9wd40rQcMxsern/NP/74Y3kTEfHJJ5807arGxsbKmyNHjjQ9a2trq7wZHR0tb/b398ubls929OjR8iYiotvtNu368RzH7Q4PbwoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEByJbWo5eJpi7m5uabdwsJCeXPz5s3yptPplDfHjh0rbyIiBgfrf7u0fL6W66ATExPlzcrKSnkT0fZvr+VnOnv2bHnD4eFNAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAyUG8Q6bX65U39+7dK29ajtTt7OyUNxFth/R2d3fLm5YjeiMjI+VNq6Ghob485+TJk315Dv9O3hQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJAcxOuDbrdb3rQcnIuIOH36dHmzuLhY3rT8TEePHi1vItq+i+3t7X/tc0ZHR8ubiLaDfX///Xd5c+bMmfKmxd7eXtNueNj/tg6SNwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACSXpQ6Zc+fOlTf7+/vlze7ubnmztrZW3kREzM/PlzctR9NWV1fLm+np6fKm9aDbyMhIedPr9cobB+eebt4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGA5BziITM2NlbeDA0NHcAnedjgYNvfIN1ut7zZ3t4ub1o+X8uV1JWVlfImIuLevXtNu6qWC7gcHt4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQHMTrg9ZDcC2Gh+u/0tnZ2fJmZGSkvGk5Htfq+PHj5U3Lz7S1tVXenDp1qryJaDukNz4+3vQsnl7eFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkBzE64Nut1vetB7Ru3v3bnmztrZW3oyOjpY3q6ur5U2rliN/m5ub5c2dO3fKm5bDe61a/u399ttvB/BJHtZyvJGD500BgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgDJRao+aD1u16LlENxLL71U3pw9e7a8aTk4FxHR6XTKm1u3bpU3LYfq5ufny5uWnyei7djh3NxcebO8vFzecHh4UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQHIQ75D54Ycfyptnn322vOnnIbhjx46VNxsbG+XN+vp6eTM2NlbetBzei4j4448/mnZVLccEb9++Xd6cPHmyvImI6Ha75U0/j1I+6XxTACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAGuj1er3H/SGeJP260Li0tFTeRER8/vnn5c3CwkJ503LxdHV1tbyJiHjuuefKm/v375c3v/zyS3kzPT1d3ty9e7e86aeWK64tl2w//vjj8oaD500BgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBp+HF/gCdNy3G7Ft98803T7sUXXyxvtre3y5vJycny5tdffy1vIiJOnz5d3ly7dq28GRoaKm/OnDlT3iwuLpY3ERGnTp0qb1qOELYc+VteXi5vrl+/Xt5ERDz//PNNOx6NNwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACQH8f6lWo+mvfzyy+VNt9stb3Z3d8ubnZ2d8qbV3t5eX57TciBxYGCg6VmdTqe8WVpaKm9ajh3280Cig3gHy5sCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSg3h9cPPmzfJmbm6u6Vnb29vlzcTERHnTcnBuaGiovImI2NraatpVDQ/X/3NoOYjXz8OAY2Nj5c1ff/1V3pw+fbq8WVlZKW84eN4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQHMTrg6WlpfKm5dBaRNuhut3d3fKm5fBey8G5iIgHDx407arW1tbKm5afaX9/v7yJaPvdnj9/vry5fv16edPyM925c6e8iYj4559/ypuZmZmmZz2NvCkAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgDJldQ+aLlu2e12m541NjZW3mxubpY3LZdLR0ZGypuIiKGhofKm5crsxsZGedNyJfXo0aPlTUTE8vJyefPqq6+WN99//315Mzc3V960/HcR0XbN1pXUR+dNAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAyUG8PlhdXS1vdnd3m541Oztb3ly9erW82draKm+mpqbKm4i276LlUN29e/fKm5bP1ul0ypuIiMXFxfLm3XffLW+OHz9e3rR8Dy2H7SLaD+nxaLwpAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgOYjXBysrK+VNt9ttetaJEyfKm/X19fJmf3+/vHnmmWfKm4i2Y2vT09Plzfj4eHnT+nvql4mJifKm5bsbGBgob1q+74iIP//8s7x54YUXmp71NPKmAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGA5CBeH9y/f7+8GRsba3rW2tpa065qe3u7vBkZGWl61t7eXnnTcoRwdna2vGn53bZ8ttbdjRs3ypvBwfrfir1er7xpOaIXEbGxsdG049F4UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIrqX1w/fr18ub8+fNNz2q5Xtqi2+2WN5ubm03P6nQ65c2bb75Z3nz55ZflTcsF17fffru8iWj7zls26+vr5U3LVd+FhYXyJiLiwoULTTsejTcFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgCkgV6v13vcH+KwazmaNjzcdquw5QDa4GD9b4MbN26UN/Pz8+VNRMTS0lJ503pQEJ523hQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJAcxAMgeVMAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIP0H0HNi3wMc8VUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bLVhXs3xrUD0"
      },
      "outputs": [],
      "source": [
        "# Normalize pixel values between 0 and 1 (Normalization)\n",
        "img_train = img_train.astype('float32') / 255.0\n",
        "img_test = img_test.astype('float32') / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_train[0]"
      ],
      "metadata": {
        "id": "v0-JRotRVDS9",
        "outputId": "c6af1b4e-8ff6-4934-f928-f96b1ff2e734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "        0.05098039, 0.28627452, 0.        , 0.        , 0.00392157,\n",
              "        0.01568628, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.00392157, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.        , 0.14117648,\n",
              "        0.53333336, 0.49803922, 0.24313726, 0.21176471, 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568628,\n",
              "        0.        , 0.        , 0.01176471],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
              "        0.8       , 0.6901961 , 0.5254902 , 0.5647059 , 0.48235294,\n",
              "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04705882, 0.03921569, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.60784316,\n",
              "        0.9254902 , 0.8117647 , 0.69803923, 0.41960785, 0.6117647 ,\n",
              "        0.6313726 , 0.42745098, 0.2509804 , 0.09019608, 0.3019608 ,\n",
              "        0.50980395, 0.28235295, 0.05882353],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.27058825, 0.8117647 ,\n",
              "        0.8745098 , 0.85490197, 0.84705883, 0.84705883, 0.6392157 ,\n",
              "        0.49803922, 0.4745098 , 0.47843137, 0.57254905, 0.5529412 ,\n",
              "        0.34509805, 0.6745098 , 0.25882354],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.        , 0.78431374, 0.9098039 ,\n",
              "        0.9098039 , 0.9137255 , 0.8980392 , 0.8745098 , 0.8745098 ,\n",
              "        0.84313726, 0.8352941 , 0.6431373 , 0.49803922, 0.48235294,\n",
              "        0.76862746, 0.8980392 , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.7176471 , 0.88235295,\n",
              "        0.84705883, 0.8745098 , 0.89411765, 0.92156863, 0.8901961 ,\n",
              "        0.8784314 , 0.87058824, 0.8784314 , 0.8666667 , 0.8745098 ,\n",
              "        0.9607843 , 0.6784314 , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.75686276, 0.89411765,\n",
              "        0.85490197, 0.8352941 , 0.7764706 , 0.7058824 , 0.83137256,\n",
              "        0.8235294 , 0.827451  , 0.8352941 , 0.8745098 , 0.8627451 ,\n",
              "        0.9529412 , 0.7921569 , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.01176471, 0.        , 0.04705882, 0.85882354, 0.8627451 ,\n",
              "        0.83137256, 0.85490197, 0.7529412 , 0.6627451 , 0.8901961 ,\n",
              "        0.8156863 , 0.85490197, 0.8784314 , 0.83137256, 0.8862745 ,\n",
              "        0.77254903, 0.81960785, 0.20392157],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.        , 0.3882353 , 0.95686275, 0.87058824,\n",
              "        0.8627451 , 0.85490197, 0.79607844, 0.7764706 , 0.8666667 ,\n",
              "        0.84313726, 0.8352941 , 0.87058824, 0.8627451 , 0.9607843 ,\n",
              "        0.46666667, 0.654902  , 0.21960784],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01568628,\n",
              "        0.        , 0.        , 0.21568628, 0.9254902 , 0.89411765,\n",
              "        0.9019608 , 0.89411765, 0.9411765 , 0.9098039 , 0.8352941 ,\n",
              "        0.85490197, 0.8745098 , 0.91764706, 0.8509804 , 0.8509804 ,\n",
              "        0.81960785, 0.36078432, 0.        ],\n",
              "       [0.        , 0.        , 0.00392157, 0.01568628, 0.02352941,\n",
              "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.92941177, 0.8862745 , 0.8509804 ,\n",
              "        0.8745098 , 0.87058824, 0.85882354, 0.87058824, 0.8666667 ,\n",
              "        0.84705883, 0.8745098 , 0.8980392 , 0.84313726, 0.85490197,\n",
              "        1.        , 0.3019608 , 0.        ],\n",
              "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.24313726,\n",
              "        0.5686275 , 0.8       , 0.89411765, 0.8117647 , 0.8352941 ,\n",
              "        0.8666667 , 0.85490197, 0.8156863 , 0.827451  , 0.85490197,\n",
              "        0.8784314 , 0.8745098 , 0.85882354, 0.84313726, 0.8784314 ,\n",
              "        0.95686275, 0.62352943, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
              "        0.17254902, 0.32156864, 0.41960785, 0.7411765 , 0.89411765,\n",
              "        0.8627451 , 0.87058824, 0.8509804 , 0.8862745 , 0.78431374,\n",
              "        0.8039216 , 0.827451  , 0.9019608 , 0.8784314 , 0.91764706,\n",
              "        0.6901961 , 0.7372549 , 0.98039216, 0.972549  , 0.9137255 ,\n",
              "        0.93333334, 0.84313726, 0.        ],\n",
              "       [0.        , 0.22352941, 0.73333335, 0.8156863 , 0.8784314 ,\n",
              "        0.8666667 , 0.8784314 , 0.8156863 , 0.8       , 0.8392157 ,\n",
              "        0.8156863 , 0.81960785, 0.78431374, 0.62352943, 0.9607843 ,\n",
              "        0.75686276, 0.80784315, 0.8745098 , 1.        , 1.        ,\n",
              "        0.8666667 , 0.91764706, 0.8666667 , 0.827451  , 0.8627451 ,\n",
              "        0.9098039 , 0.9647059 , 0.        ],\n",
              "       [0.01176471, 0.7921569 , 0.89411765, 0.8784314 , 0.8666667 ,\n",
              "        0.827451  , 0.827451  , 0.8392157 , 0.8039216 , 0.8039216 ,\n",
              "        0.8039216 , 0.8627451 , 0.9411765 , 0.3137255 , 0.5882353 ,\n",
              "        1.        , 0.8980392 , 0.8666667 , 0.7372549 , 0.6039216 ,\n",
              "        0.7490196 , 0.8235294 , 0.8       , 0.81960785, 0.87058824,\n",
              "        0.89411765, 0.88235295, 0.        ],\n",
              "       [0.38431373, 0.9137255 , 0.7764706 , 0.8235294 , 0.87058824,\n",
              "        0.8980392 , 0.8980392 , 0.91764706, 0.9764706 , 0.8627451 ,\n",
              "        0.7607843 , 0.84313726, 0.8509804 , 0.94509804, 0.25490198,\n",
              "        0.28627452, 0.41568628, 0.45882353, 0.65882355, 0.85882354,\n",
              "        0.8666667 , 0.84313726, 0.8509804 , 0.8745098 , 0.8745098 ,\n",
              "        0.8784314 , 0.8980392 , 0.11372549],\n",
              "       [0.29411766, 0.8       , 0.83137256, 0.8       , 0.75686276,\n",
              "        0.8039216 , 0.827451  , 0.88235295, 0.84705883, 0.7254902 ,\n",
              "        0.77254903, 0.80784315, 0.7764706 , 0.8352941 , 0.9411765 ,\n",
              "        0.7647059 , 0.8901961 , 0.9607843 , 0.9372549 , 0.8745098 ,\n",
              "        0.85490197, 0.83137256, 0.81960785, 0.87058824, 0.8627451 ,\n",
              "        0.8666667 , 0.9019608 , 0.2627451 ],\n",
              "       [0.1882353 , 0.79607844, 0.7176471 , 0.7607843 , 0.8352941 ,\n",
              "        0.77254903, 0.7254902 , 0.74509805, 0.7607843 , 0.7529412 ,\n",
              "        0.7921569 , 0.8392157 , 0.85882354, 0.8666667 , 0.8627451 ,\n",
              "        0.9254902 , 0.88235295, 0.84705883, 0.78039217, 0.80784315,\n",
              "        0.7294118 , 0.70980394, 0.69411767, 0.6745098 , 0.70980394,\n",
              "        0.8039216 , 0.80784315, 0.4509804 ],\n",
              "       [0.        , 0.47843137, 0.85882354, 0.75686276, 0.7019608 ,\n",
              "        0.67058825, 0.7176471 , 0.76862746, 0.8       , 0.8235294 ,\n",
              "        0.8352941 , 0.8117647 , 0.827451  , 0.8235294 , 0.78431374,\n",
              "        0.76862746, 0.7607843 , 0.7490196 , 0.7647059 , 0.7490196 ,\n",
              "        0.7764706 , 0.7529412 , 0.6901961 , 0.6117647 , 0.654902  ,\n",
              "        0.69411767, 0.8235294 , 0.36078432],\n",
              "       [0.        , 0.        , 0.2901961 , 0.7411765 , 0.83137256,\n",
              "        0.7490196 , 0.6862745 , 0.6745098 , 0.6862745 , 0.70980394,\n",
              "        0.7254902 , 0.7372549 , 0.7411765 , 0.7372549 , 0.75686276,\n",
              "        0.7764706 , 0.8       , 0.81960785, 0.8235294 , 0.8235294 ,\n",
              "        0.827451  , 0.7372549 , 0.7372549 , 0.7607843 , 0.7529412 ,\n",
              "        0.84705883, 0.6666667 , 0.        ],\n",
              "       [0.00784314, 0.        , 0.        , 0.        , 0.25882354,\n",
              "        0.78431374, 0.87058824, 0.92941177, 0.9372549 , 0.9490196 ,\n",
              "        0.9647059 , 0.9529412 , 0.95686275, 0.8666667 , 0.8627451 ,\n",
              "        0.75686276, 0.7490196 , 0.7019608 , 0.7137255 , 0.7137255 ,\n",
              "        0.70980394, 0.6901961 , 0.6509804 , 0.65882355, 0.3882353 ,\n",
              "        0.22745098, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
              "        0.28235295, 0.16078432, 0.13725491, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5YEL2H2Ax3e"
      },
      "source": [
        "## Define the model\n",
        "\n",
        "When you build a model for hypertuning, you also define the hyperparameter search space in addition to the model architecture. The model you set up for hypertuning is called a *hypermodel*.\n",
        "\n",
        "You can define a hypermodel through two approaches:\n",
        "\n",
        "* By using a model builder function\n",
        "* By subclassing the `HyperModel` class of the Keras Tuner API\n",
        "\n",
        "You can also use two pre-defined [HyperModel](https://keras.io/api/keras_tuner/hypermodels/) classes - [HyperXception](https://keras.io/api/keras_tuner/hypermodels/hyper_xception/) and [HyperResNet](https://keras.io/api/keras_tuner/hypermodels/hyper_resnet/) for computer vision applications.\n",
        "\n",
        "In this tutorial, you use a model builder function to define the image classification model. The model builder function returns a compiled model and uses hyperparameters you define inline to hypertune the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZQKodC-jtsva"
      },
      "outputs": [],
      "source": [
        "def model_builder(hp): #hp is hyperparameter tuning technique\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(28, 28))) #input layer\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32) #check for 32,64,.....,512\n",
        "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))#above is for adding one hidden layer only\n",
        "  model.add(keras.layers.Dense(10)) #output layer. default act fn softmax which is indicated by below loss function used\n",
        "\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "  #int for range\n",
        "  #choice for one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J1VYw4q3x0b"
      },
      "source": [
        "## Instantiate the tuner and perform hypertuning\n",
        "\n",
        "Instantiate the tuner to perform the hypertuning. The Keras Tuner has four tuners available - `RandomSearch`, `Hyperband`, `BayesianOptimization`, and `Sklearn`. In this tutorial, you use the [Hyperband](https://arxiv.org/pdf/1603.06560.pdf) tuner.\n",
        "\n",
        "To instantiate the Hyperband tuner, you must specify the hypermodel, the `objective` to optimize and the maximum number of epochs to train (`max_epochs`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oichQFly6Y46"
      },
      "outputs": [],
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaIhhdKf9VtI"
      },
      "source": [
        "The Hyperband tuning algorithm uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model. This is done using a sports championship style bracket. The algorithm trains a large number of models for a few epochs and carries forward only the top-performing half of models to the next round. Hyperband determines the number of models to train in a bracket by computing 1 + log<sub>`factor`</sub>(`max_epochs`) and rounding it up to the nearest integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwhBdXx0Ekj8"
      },
      "source": [
        "Create a callback to stop training early after reaching a certain value for the validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WT9IkS9NEjLc"
      },
      "outputs": [],
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKghEo15Tduy"
      },
      "source": [
        "Run the hyperparameter search. The arguments for the search method are the same as those used for `tf.keras.model.fit` in addition to the callback above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dSBQcTHF9cKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22087c8-4fb4-478c-a584-17315afbb456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 01m 23s]\n",
            "val_accuracy: 0.8773333430290222\n",
            "\n",
            "Best val_accuracy So Far: 0.8922500014305115\n",
            "Total elapsed time: 00h 12m 42s\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 480 and the optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lak_ylf88xBv"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Find the optimal number of epochs to train the model with the hyperparameters obtained from the search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "McO82AXOuxXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7857ce42-efa6-4303-810e-7b699f092270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4960 - accuracy: 0.8261 - val_loss: 0.4011 - val_accuracy: 0.8567\n",
            "Epoch 2/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3690 - accuracy: 0.8636 - val_loss: 0.3751 - val_accuracy: 0.8592\n",
            "Epoch 3/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3305 - accuracy: 0.8791 - val_loss: 0.3528 - val_accuracy: 0.8711\n",
            "Epoch 4/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3041 - accuracy: 0.8871 - val_loss: 0.3661 - val_accuracy: 0.8693\n",
            "Epoch 5/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2889 - accuracy: 0.8920 - val_loss: 0.3636 - val_accuracy: 0.8661\n",
            "Epoch 6/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2708 - accuracy: 0.8992 - val_loss: 0.3325 - val_accuracy: 0.8802\n",
            "Epoch 7/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2580 - accuracy: 0.9022 - val_loss: 0.3379 - val_accuracy: 0.8775\n",
            "Epoch 8/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2434 - accuracy: 0.9088 - val_loss: 0.3059 - val_accuracy: 0.8926\n",
            "Epoch 9/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2340 - accuracy: 0.9114 - val_loss: 0.3088 - val_accuracy: 0.8862\n",
            "Epoch 10/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2221 - accuracy: 0.9167 - val_loss: 0.3550 - val_accuracy: 0.8754\n",
            "Epoch 11/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2153 - accuracy: 0.9179 - val_loss: 0.3276 - val_accuracy: 0.8912\n",
            "Epoch 12/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2068 - accuracy: 0.9227 - val_loss: 0.3078 - val_accuracy: 0.8948\n",
            "Epoch 13/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1994 - accuracy: 0.9246 - val_loss: 0.3179 - val_accuracy: 0.8938\n",
            "Epoch 14/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1927 - accuracy: 0.9271 - val_loss: 0.3285 - val_accuracy: 0.8920\n",
            "Epoch 15/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1844 - accuracy: 0.9316 - val_loss: 0.3090 - val_accuracy: 0.8981\n",
            "Epoch 16/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1784 - accuracy: 0.9325 - val_loss: 0.3234 - val_accuracy: 0.8935\n",
            "Epoch 17/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1731 - accuracy: 0.9360 - val_loss: 0.3261 - val_accuracy: 0.8967\n",
            "Epoch 18/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1664 - accuracy: 0.9380 - val_loss: 0.3544 - val_accuracy: 0.8869\n",
            "Epoch 19/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1643 - accuracy: 0.9376 - val_loss: 0.3349 - val_accuracy: 0.8956\n",
            "Epoch 20/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1548 - accuracy: 0.9428 - val_loss: 0.3534 - val_accuracy: 0.8931\n",
            "Epoch 21/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1525 - accuracy: 0.9426 - val_loss: 0.3613 - val_accuracy: 0.8939\n",
            "Epoch 22/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1484 - accuracy: 0.9439 - val_loss: 0.3553 - val_accuracy: 0.8926\n",
            "Epoch 23/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1436 - accuracy: 0.9467 - val_loss: 0.3812 - val_accuracy: 0.8918\n",
            "Epoch 24/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1382 - accuracy: 0.9478 - val_loss: 0.3627 - val_accuracy: 0.8954\n",
            "Epoch 25/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1355 - accuracy: 0.9492 - val_loss: 0.3888 - val_accuracy: 0.8928\n",
            "Epoch 26/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1297 - accuracy: 0.9515 - val_loss: 0.3814 - val_accuracy: 0.8928\n",
            "Epoch 27/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1264 - accuracy: 0.9522 - val_loss: 0.3980 - val_accuracy: 0.8915\n",
            "Epoch 28/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1235 - accuracy: 0.9532 - val_loss: 0.3896 - val_accuracy: 0.8950\n",
            "Epoch 29/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1226 - accuracy: 0.9547 - val_loss: 0.3819 - val_accuracy: 0.8950\n",
            "Epoch 30/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1189 - accuracy: 0.9551 - val_loss: 0.3895 - val_accuracy: 0.8962\n",
            "Epoch 31/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1148 - accuracy: 0.9567 - val_loss: 0.4145 - val_accuracy: 0.8942\n",
            "Epoch 32/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1146 - accuracy: 0.9567 - val_loss: 0.4239 - val_accuracy: 0.8939\n",
            "Epoch 33/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1064 - accuracy: 0.9601 - val_loss: 0.4369 - val_accuracy: 0.8910\n",
            "Epoch 34/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1066 - accuracy: 0.9597 - val_loss: 0.4523 - val_accuracy: 0.8895\n",
            "Epoch 35/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1047 - accuracy: 0.9610 - val_loss: 0.4396 - val_accuracy: 0.8947\n",
            "Epoch 36/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1055 - accuracy: 0.9594 - val_loss: 0.4318 - val_accuracy: 0.8972\n",
            "Epoch 37/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0985 - accuracy: 0.9629 - val_loss: 0.4726 - val_accuracy: 0.8940\n",
            "Epoch 38/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0954 - accuracy: 0.9640 - val_loss: 0.4338 - val_accuracy: 0.8971\n",
            "Epoch 39/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0959 - accuracy: 0.9637 - val_loss: 0.4603 - val_accuracy: 0.8907\n",
            "Epoch 40/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0918 - accuracy: 0.9649 - val_loss: 0.4849 - val_accuracy: 0.8954\n",
            "Epoch 41/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0943 - accuracy: 0.9658 - val_loss: 0.4928 - val_accuracy: 0.8898\n",
            "Epoch 42/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0887 - accuracy: 0.9665 - val_loss: 0.4945 - val_accuracy: 0.8913\n",
            "Epoch 43/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0881 - accuracy: 0.9675 - val_loss: 0.5058 - val_accuracy: 0.8905\n",
            "Epoch 44/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0873 - accuracy: 0.9682 - val_loss: 0.5213 - val_accuracy: 0.8910\n",
            "Epoch 45/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0848 - accuracy: 0.9673 - val_loss: 0.5095 - val_accuracy: 0.8892\n",
            "Epoch 46/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0815 - accuracy: 0.9686 - val_loss: 0.5220 - val_accuracy: 0.8931\n",
            "Epoch 47/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0783 - accuracy: 0.9710 - val_loss: 0.5300 - val_accuracy: 0.8925\n",
            "Epoch 48/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0793 - accuracy: 0.9704 - val_loss: 0.5416 - val_accuracy: 0.8922\n",
            "Epoch 49/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0732 - accuracy: 0.9735 - val_loss: 0.5392 - val_accuracy: 0.8940\n",
            "Epoch 50/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0770 - accuracy: 0.9716 - val_loss: 0.5687 - val_accuracy: 0.8953\n",
            "Best epoch: 15\n"
          ]
        }
      ],
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOTSirSTI3Gp"
      },
      "source": [
        "Re-instantiate the hypermodel and train it with the optimal number of epochs from above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NoiPUEHmMhCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7d0b39-0e0c-482f-ba84-95dffd25e30e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4940 - accuracy: 0.8241 - val_loss: 0.4253 - val_accuracy: 0.8453\n",
            "Epoch 2/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3682 - accuracy: 0.8651 - val_loss: 0.3527 - val_accuracy: 0.8718\n",
            "Epoch 3/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3305 - accuracy: 0.8780 - val_loss: 0.3651 - val_accuracy: 0.8691\n",
            "Epoch 4/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3045 - accuracy: 0.8873 - val_loss: 0.3439 - val_accuracy: 0.8761\n",
            "Epoch 5/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2864 - accuracy: 0.8932 - val_loss: 0.3325 - val_accuracy: 0.8821\n",
            "Epoch 6/15\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.2700 - accuracy: 0.8996 - val_loss: 0.3158 - val_accuracy: 0.8814\n",
            "Epoch 7/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2544 - accuracy: 0.9062 - val_loss: 0.3159 - val_accuracy: 0.8868\n",
            "Epoch 8/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2436 - accuracy: 0.9084 - val_loss: 0.3261 - val_accuracy: 0.8834\n",
            "Epoch 9/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2368 - accuracy: 0.9103 - val_loss: 0.3301 - val_accuracy: 0.8831\n",
            "Epoch 10/15\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2235 - accuracy: 0.9154 - val_loss: 0.3274 - val_accuracy: 0.8837\n",
            "Epoch 11/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2135 - accuracy: 0.9203 - val_loss: 0.3175 - val_accuracy: 0.8907\n",
            "Epoch 12/15\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2076 - accuracy: 0.9228 - val_loss: 0.3306 - val_accuracy: 0.8898\n",
            "Epoch 13/15\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2006 - accuracy: 0.9251 - val_loss: 0.3470 - val_accuracy: 0.8877\n",
            "Epoch 14/15\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1935 - accuracy: 0.9264 - val_loss: 0.3208 - val_accuracy: 0.8902\n",
            "Epoch 15/15\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1833 - accuracy: 0.9313 - val_loss: 0.3483 - val_accuracy: 0.8901\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c0f84c21f90>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqU5ZVAaag2v"
      },
      "source": [
        "To finish this tutorial, evaluate the hypermodel on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9E0BTp9Ealjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14f630af-b6fb-4482-e8af-51f3215baabd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3777 - accuracy: 0.8832\n",
            "[test loss, test accuracy]: [0.37766891717910767, 0.8831999897956848]\n"
          ]
        }
      ],
      "source": [
        "eval_result = hypermodel.evaluate(img_test, label_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQRpPHZsz-eC"
      },
      "source": [
        "The `my_dir/intro_to_kt` directory contains detailed logs and checkpoints for every trial (model configuration) run during the hyperparameter search. If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. To disable this behavior, pass an additional `overwrite=True` argument while instantiating the tuner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKwLOzKpFGAj"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, you learned how to use the Keras Tuner to tune hyperparameters for a model. To learn more about the Keras Tuner, check out these additional resources:\n",
        "\n",
        "* [Keras Tuner on the TensorFlow blog](https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html)\n",
        "* [Keras Tuner website](https://keras-team.github.io/keras-tuner/)\n",
        "\n",
        "Also check out the [HParams Dashboard](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams) in TensorBoard to interactively tune your model hyperparameters."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}